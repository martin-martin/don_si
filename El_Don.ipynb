{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing a free-form literary Corpus for word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt.1 - Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"Spanish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import literature\n",
    "# Thanks Project Gutenberg: http://www.gutenberg.org/cache/epub/2000/pg2000.txt\n",
    "file_path = \"cervantes_quijote.txt\"\n",
    "text = Path(file_path).read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt.2 - Getting the data in shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will separate the companion info text from the actual novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this final intro word is gleaned from checking out the text string\n",
    "text_info_end = \"Abela.\"\n",
    "info_end_index = text.find(text_info_end)\n",
    "info_end = info_end_index + len(text_info_end)\n",
    "# creating a variable holding the text info\n",
    "text_info = text[: info_end]\n",
    "# and another one with the Spanish novel\n",
    "dq_start = text.find(\"El ingenioso hidalgo\")\n",
    "don_quijote = text[dq_start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "TASA\n",
      "\n",
      "Yo, Juan Gallo de Andrada, escribano de Cámara del Rey nuestro señor, de\n",
      "los que residen en su Consejo, certifico y doy fe que, habiendo visto por\n",
      "los señores dél un libro intitulado El ingenioso hidalgo de la Mancha,\n",
      "compuesto por Miguel de Cervantes Saavedra, tasaron cada pliego del dicho\n",
      "libro a tres maravedís y medio; el cual tiene ochenta y tres pliegos, que\n",
      "al dicho precio monta el dicho libro docientos y noventa maravedís y medio,\n",
      "en q\n"
     ]
    }
   ],
   "source": [
    "print(don_quijote[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll remove newlines while keeping \"sentence\" information. For this I will treat headings as \"sentences\" and as separate pieces of meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingenioso hidalgo don Quijote de la Mancha. TASA. Yo, Juan Gallo de Andrada, escribano de Cámara del Rey nuestro señor, de\n",
      "los que residen en su Consejo, certifico y doy fe que, habiendo visto por\n",
      "los señores dél un libro intitulado El ingenioso hidalgo de la Mancha,\n",
      "compuesto por Miguel de Cervantes Saavedra, tasaron cada pliego del dicho\n",
      "libro a tres maravedís y medio; el cual tiene ochenta y tres pliegos, que\n",
      "al dicho precio monta el dicho libro docientos y noventa maravedís y medio,\n",
      "en qu\n"
     ]
    }
   ],
   "source": [
    "# this regex pipe replaces all occurances of at least 2 consecutive newlines\n",
    "# with a dot followed by a whitespace\n",
    "# if the line before the first newline character ends with a letter (not a sentence delimiter)\n",
    "regex =  re.compile(r\"(?<=\\w)\\n{2,}\")\n",
    "don_quijote = re.sub(regex, \". \", don_quijote)\n",
    "print(don_quijote[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good. Now I'll also remove the remaining newlines, replacing them simply with whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El ingenioso hidalgo don Quijote de la Mancha. TASA. Yo, Juan Gallo de Andrada, escribano de Cámara del Rey nuestro señor, de los que residen en su Consejo, certifico y doy fe que, habiendo visto por los señores dél un libro intitulado El ingenioso hidalgo de la Mancha, compuesto por Miguel de Cervantes Saavedra, tasaron cada pliego del dicho libro a tres maravedís y medio; el cual tiene ochenta y tres pliegos, que al dicho precio monta el dicho libro docientos y noventa maravedís y medio, en qu'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "don_quijote = don_quijote.replace(\"\\n\", \" \")\n",
    "don_quijote[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt.3 - Splitting the data in pieces (tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since for this exercise I am treating the novel as a **Spanish corpus**, I now go to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9848\n"
     ]
    }
   ],
   "source": [
    "dq_sent_tokenized = nltk.sent_tokenize(don_quijote)\n",
    "# I won't be using the tokenized sentences here, but let's see how many there are\n",
    "print(len(dq_sent_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looking for word frequencies, I'll need the words tokenized\n",
    "dq_word_tokenized = nltk.word_tokenize(don_quijote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt.4 - Getting the word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The NLTK book](http://www.nltk.org/book/ch01.html) provides a useful library for calculating word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.book import FreqDist\n",
    "fdist = FreqDist(dq_word_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 26426 samples and 441946 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 40316),\n",
       " ('que', 20520),\n",
       " ('de', 17990),\n",
       " ('y', 17155),\n",
       " ('la', 10201),\n",
       " ('a', 9579),\n",
       " ('.', 8306),\n",
       " ('el', 7959),\n",
       " ('en', 7900),\n",
       " ('no', 5764),\n",
       " (';', 4802),\n",
       " ('se', 4691),\n",
       " ('los', 4681),\n",
       " ('con', 4048),\n",
       " ('por', 3758),\n",
       " ('las', 3423),\n",
       " ('lo', 3389),\n",
       " ('le', 3382),\n",
       " ('su', 3320),\n",
       " ('don', 2538)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, neat. Let's remove the stopwords and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing stopwords and translating all words to lowercase\n",
    "dq_real_words = [w.lower() for w in dq_word_tokenized if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing punctuation\n",
    "dq_words = [w for w in dq_real_words if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdist = FreqDist(dq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 23176 samples and 183370 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('don', 2646),\n",
       " ('si', 1895),\n",
       " ('quijote', 1655),\n",
       " ('sancho', 1626),\n",
       " ('tan', 1220),\n",
       " ('ser', 1056),\n",
       " ('bien', 990),\n",
       " ('señor', 979),\n",
       " ('así', 964),\n",
       " ('dijo', 929),\n",
       " ('y', 908),\n",
       " ('merced', 900),\n",
       " ('pues', 721),\n",
       " ('sino', 694),\n",
       " ('dos', 680),\n",
       " ('caballero', 646),\n",
       " ('decir', 578),\n",
       " ('hacer', 535),\n",
       " ('aunque', 527),\n",
       " ('señora', 508)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. With inspecting the corpus and a bit of data wrangling here are the word frequencies of Cervantes' Don Quijote."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car]",
   "language": "python",
   "name": "conda-env-car-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
